{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the total number of enteries in the dataset:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144648288\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "count=0\n",
    "for i in range(0,500):\n",
    "    num=str(i)\n",
    "    zero_fill_num=num.zfill(5)\n",
    "    with gzip.open('/ichec/work/mucom001c/GoogleSvrLog/clusterdata-2011-1/task_events/part-'+zero_fill_num+'-of-00500.csv.gz', 'rb') as f:\n",
    "        for line in f:\n",
    "            line=line.decode()\n",
    "            line=line.split(',')\n",
    "            t=line[0]\n",
    "            count+=1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of enteries in the files are :144648288\n",
    "\n",
    "Average entry per file :289296.5\n",
    "\n",
    "Data attributes in the file :8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the file size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1624496362\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "for i in range(0,500):\n",
    "    num=str(i)\n",
    "    zero_fill_num=num.zfill(5)\n",
    "    size+=Path('/ichec/work/mucom001c/GoogleSvrLog/clusterdata-2011-1/task_events/part-'+zero_fill_num+'-of-00500.csv.gz').stat().st_size\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total file size of the Zipped file :1624496362 byte or 1.62 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset using spark since the data size is big :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def setup_my_environment():\n",
    "    import os\n",
    "    \n",
    "def setenv(var, val):\n",
    "    os.environ[var] = val\n",
    "\n",
    "def prepend_path(var, val):\n",
    "    old_val = os.environ.get(var, '')\n",
    "    os.environ[var] = val + \":\" + old_val\n",
    "    \n",
    "def setup_java():\n",
    "    PKG_ROOT='/ichec/packages/java/8'\n",
    "    setenv('JAVA_PATH', PKG_ROOT)\n",
    "    setenv('JAVA_HOME', PKG_ROOT)\n",
    "    prepend_path('PATH', PKG_ROOT + '/bin')\n",
    "    prepend_path('MANPATH', PKG_ROOT + '/man')\n",
    "    prepend_path('CPATH', PKG_ROOT + '/include')\n",
    "    \n",
    "def setup_spark():\n",
    "    PKG_ROOT='/ichec/packages/spark/2.3.3/kay/spark-2.3.3'\n",
    "    setenv('SPARK_DIST_CLASSPATH', PKG_ROOT + 'spark-2.3.3-bin-kay-spark')\n",
    "    prepend_path('PATH', PKG_ROOT + PKG_ROOT + 'spark-2.3.3-bin-kay-spark/bin')\n",
    "setup_java()\n",
    "setup_spark()\n",
    "setup_my_environment()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    " \n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"5g\") \\\n",
    "    .config(\"spark.executor.instances\",\"20\")\\\n",
    "    .config(\"spark.executor.cores\",\"2\")\\\n",
    "    .config(\"spark.worker.instances\",\"20\")\\\n",
    "    .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "    .config(\"spark.memory.offHeap.size\",\"25g\")\\\n",
    "    .config(\"spark.debug.maxToStringsFields\",\"100\")\\\n",
    "    .appName(\"GoogleSvrLog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/ichec/work/mucom001c/GoogleSvrLog/clusterdata-2011-1/task_events/*.gz\")\n",
    "df5=df.select('_c0','_c2','_c3','_c5','_c8','_c9','_c10','_c11')\n",
    "df5=df5.selectExpr('_c0 as time','_c2 as job_id','_c3 as task_index','_c5 as event_type','_c8 as priority','_c9 as cpu_request','_c10 as memory_request','_c11 as disk_space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "|        time|    job_id|task_index|event_type|priority|cpu_request|memory_request|disk_space|\n",
      "+------------+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "|807403811171|6324858588|      8323|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|807403811182|6324858588|      8323|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|807403811183|6324858588|      9024|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|807403811194|6324858588|      9024|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|807403811195|6324858588|      7152|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "+------------+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting the time unix time stamp to the date in which the task was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df5new = df5.withColumn('time', from_unixtime(df5.time, \"dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "|time|    job_id|task_index|event_type|priority|cpu_request|memory_request|disk_space|\n",
      "+----+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "|  11|6324858588|      8323|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|      8323|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|      9024|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|      9024|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|      7152|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|      7152|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13525|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13525|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6325302687|      2547|         4|       6|    0.04376|      0.004089|  0.000309|\n",
      "|  11|6324858588|     13410|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13410|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13513|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13513|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13481|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13481|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13496|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13496|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13452|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13452|         0|       0|     0.0125|        0.0159| 0.0004044|\n",
      "|  11|6324858588|     13510|         3|       0|     0.0125|        0.0159| 0.0004044|\n",
      "+----+----------+----------+----------+--------+-----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5new.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|time|\n",
      "+----+\n",
      "|  07|\n",
      "|  15|\n",
      "|  11|\n",
      "|  29|\n",
      "|  30|\n",
      "|  01|\n",
      "|  22|\n",
      "|  28|\n",
      "|  16|\n",
      "|null|\n",
      "|  31|\n",
      "|  18|\n",
      "|  27|\n",
      "|  17|\n",
      "|  26|\n",
      "|  09|\n",
      "|  05|\n",
      "|  19|\n",
      "|  23|\n",
      "|  08|\n",
      "|  03|\n",
      "|  25|\n",
      "|  02|\n",
      "|  06|\n",
      "|  24|\n",
      "|  20|\n",
      "|  10|\n",
      "|  12|\n",
      "|  04|\n",
      "|  13|\n",
      "|  21|\n",
      "|  14|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5new.select('time').distinct().show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5new=df5new.groupBy('time','event_type','disk_space',\"cpu_request\",'memory_request').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761066"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5new.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing the time of the given data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+-----------+--------------+------+\n",
      "|time|event_type|disk_space|cpu_request|memory_request| count|\n",
      "+----+----------+----------+-----------+--------------+------+\n",
      "|  11|         0| 0.0001154|      0.125|       0.04773|  2306|\n",
      "|  06|         2| 0.0003862|     0.0625|       0.07959|    13|\n",
      "|  12|         2| 0.0001154|    0.06873|       0.01193|  9944|\n",
      "|  29|         1| 5.436e-05|      0.125|       0.07959|  2404|\n",
      "|  24|         2| 0.0001154|      0.125|       0.04773|   109|\n",
      "|  25|         0| 0.0004044|     0.0125|        0.0159|400619|\n",
      "|  25|         0|  0.001131|    0.03125|       0.07764|   221|\n",
      "|  09|         5|  2.67e-05|    0.01874|      0.003109|  1081|\n",
      "|  20|         0|         0|   0.003124|     6.199e-05|    45|\n",
      "|  14|         1|  0.001131|    0.03125|       0.07764|   287|\n",
      "+----+----------+----------+-----------+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5new.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5new=df5new.repartition(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5new.write.csv(\"/ichec/home/users/nishantk2106/final_dataset.csv\",\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-myproj]",
   "language": "python",
   "name": "conda-env-.conda-myproj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
